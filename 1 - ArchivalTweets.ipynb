{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058b109b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "\n",
    "import tweepy \n",
    "import re\n",
    "## Preprocessing \n",
    "import pandas as pd \n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4598049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize api instance - Taori's Academic Research Account Creds\n",
    "\n",
    "# ACCESS_TOKEN = \"....\"\n",
    "# ACCESS_TOKEN_SECRET = \"...\"\n",
    "# CONSUMER_KEY = \"....\"\n",
    "# CONSUMER_SECRET = \"...\"\n",
    "BEARER_TOKEN = \"....\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b954d997",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect to Twitter through the API \n",
    "\n",
    "# auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET) \n",
    "# auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET) \n",
    "# api = tweepy.API(auth,wait_on_rate_limit=True)\n",
    "\n",
    "# To use tweepy v2 version, we need only bearer token\n",
    "client = tweepy.Client(bearer_token=BEARER_TOKEN, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84bd307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lat Long of 10 cities\n",
    "\n",
    "NYC = {'lat': 40.712776, 'long': -74.005974}\n",
    "LA = {'lat': 34.052235, 'long': -118.243683}\n",
    "CHICAGO = {'lat': 41.878113, 'long': -87.629799}\n",
    "BOSTON = {'lat': 42.360081, 'long': -71.058884}\n",
    "NASHVILLE = {'lat': 36.162663, 'long': -86.781601}\n",
    "DALLAS = {'lat': 32.776665, 'long': -96.796989}\n",
    "SEATTLE = {'lat': 47.606209, 'long': -122.332069}\n",
    "DENVER = {'lat': 39.739235, 'long': -104.990250}\n",
    "NEW_ORLEANS = {'lat': 29.951065, 'long': -90.071533}\n",
    "INDIANAPOLIS = {'lat': 39.768402, 'long': -86.158066}\n",
    "\n",
    "RADIUS = \"25mi\"\n",
    "\n",
    "# cities = {\"NewYork\": NYC, \"LA\": LA, \"Chicago\": CHICAGO}\n",
    "cities = {\"INDIANAPOLIS\": INDIANAPOLIS}\n",
    "# geo = ' '.join(str(item) for item in NYC.values()) + \" \" + RADIUS\n",
    "# geo = \"[{} {} {}]\".format(NYC.get('long'), NYC.get('lat'), RADIUS)\n",
    "# geo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cf6a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# out = client.search_all_tweets(query=\"(iphone15\", max_results=500, start_time=\"2022-01-01T00:00:00.000000+00:00\", expansions=\"geo.place_id,author_id\", user_fields=\"public_metrics,verified\", tweet_fields=\"created_at\")\n",
    "# out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc3cd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAX_TWEETS = 5000\n",
    "# RADIUS = \"25mi\"\n",
    "# COUNT_PER_PAGE = 100\n",
    "# tweets_for_cities = defaultdict(list)\n",
    "\n",
    "# def retrieve_and_store_tweets(search_query, lat_long, city_name):\n",
    "#     tweets = tweepy.Cursor(api.search_tweets, q = search_query, geocode = lat_long, count = COUNT_PER_PAGE).items(MAX_TWEETS)\n",
    "    \n",
    "#     # Pulling information from tweets iterable object\n",
    "#     # Add or remove tweet information you want in the below list comprehension\n",
    "#     tweets_list = [[tweet.text, tweet.created_at, tweet.id_str, tweet.favorite_count, tweet.user.screen_name, tweet.user.id_str, tweet.user.location, tweet.user.followers_count, tweet.coordinates, tweet.place] for tweet in tweets]\n",
    "\n",
    "#     # Creation of dataframe from tweets_list\n",
    "#     # Did not include column names to simplify code\n",
    "#     tweets_df = pd.DataFrame(tweets_list)\n",
    "    \n",
    "#     tweets_for_cities[city_name].append(tweets_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c9079e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of keywords related to crime\n",
    "\n",
    "sectors_and_topics = defaultdict(list)\n",
    "sectors_and_topics[\"Crime\"].extend([\"Crime\", \"Theft\", \"Violence\", \"Gun Violence\", \"Abscond\", \"Harassmemt\", \n",
    "                                            \"SexualAbuse\", \"Assault\", \"Bribe\", \"Burglar\", \"Offense\", \"Unlawful\", \n",
    "                                            \"Forgery\", \"Illegal\", \"Gambling\", \"Violation\", \"Homicide\", \n",
    "                                            \"Imprisonment\", \"Trafficking\", \"Extrotion\", \"Manslaughter\", \"Criminal\", \n",
    "                                            \"Perjury\", \"Robbery\", \"Terrorism\", \"Terrorist\"])\n",
    "\n",
    "# retrieve_and_store_tweets(query, ','.join(str(item) for item in NYC.values()) + \",\" + RADIUS, \"NewYork\")\n",
    "\n",
    "# api.search_full_archive(label=\"dev\", query=\"crime\", fromDate=\"201101010000\", toDate=\"20211231000\", maxResults=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66c0ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query building\n",
    "\n",
    "query = \" OR \".join(list(sectors_and_topics[\"Crime\"]))\n",
    "# point_radius = \"[{} {} {}]\".format(NYC.get('long'), NYC.get('lat'), RADIUS)\n",
    "# query = \"(\" + query + \")\" + \" point_radius:\" + point_radius\n",
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27857229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# out = client.search_all_tweets(query=query, max_results=500, start_time=\"2022-01-17T00:00:00.000000+00:00\", expansions=\"geo.place_id,author_id\", user_fields=\"public_metrics,verified\", tweet_fields=\"created_at\")\n",
    "# next_token = out.meta.get('next_token')\n",
    "# tweet_text_1 = out.data[0].text\n",
    "# out = client.search_all_tweets(query=query, max_results=500, start_time=\"2022-01-17T00:00:00.000000+00:00\", expansions=\"geo.place_id,author_id\", user_fields=\"public_metrics,verified\", tweet_fields=\"created_at\", next_token=next_token)\n",
    "# out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20290cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fetch all archival tweets with pagination\n",
    "\n",
    "total_tweets_per_city_per_month = 50000\n",
    "MAX_TWEETS = 500\n",
    "tweets_per_page = total_tweets_per_city_per_month // MAX_TWEETS\n",
    "\n",
    "def fetch_and_store_archival_tweets(city_name, query, start_time, end_time, month, year):\n",
    "    next_token = \"\"\n",
    "\n",
    "    # Name and path of the file where you want the Tweets written to\n",
    "    file_name = \"INDIANAPOLIS.csv\"\n",
    "\n",
    "    with open(file_name, 'a') as filehandle:\n",
    "        for i in range(0, tweets_per_page):\n",
    "            if not next_token:\n",
    "                out = client.search_all_tweets(query=query, max_results=500, start_time=start_time, end_time=end_time, expansions=\"geo.place_id\")\n",
    "            else:\n",
    "                out = client.search_all_tweets(query=query, max_results=500, start_time=start_time, end_time=end_time, expansions=\"geo.place_id\", next_token=next_token)\n",
    "            \n",
    "            if (not out) or (not out.data):\n",
    "                return\n",
    "            \n",
    "            for data in out.data:\n",
    "                df = pd.DataFrame({\"tweet\": data.text, \"tweet_id\": data.id, \"month\": \"{}-{}\".format(month, year)}, index=[1])\n",
    "                df.to_csv(file_name, mode='a', index=False, header=False)\n",
    "#                 filehandle.write(\"{},{},{}\".format(data.text, month, year))\n",
    "            \n",
    "            next_token = out.meta.get('next_token')\n",
    "            if not next_token:\n",
    "                return\n",
    "\n",
    "def store_logs(start_time, end_time):\n",
    "    file_name = \"tweets_script_logs_INDIANAPOLIS.txt\"\n",
    "    \n",
    "    with open(file_name, 'a') as filehandle:\n",
    "        filehandle.write(\"{},{}\\n\".format(start_time, end_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4de9986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Driver Function to loop for time range and fetch and store tweets\n",
    "\n",
    "for city_name, geo in cities.items():\n",
    "    point_radius = \"[{} {} {}]\".format(geo.get('long'), geo.get('lat'), RADIUS)\n",
    "    query = \"(\" + query + \")\" + \" point_radius:\" + point_radius\n",
    "    for year in range(2011, 2022):\n",
    "        for month in range(1, 13):\n",
    "            if (year == 2013 and month >= 10) or (year >= 2014):\n",
    "                month = \"0{}\".format(month) if month < 10 else month\n",
    "                start_time = \"{}-{}-01T00:00:00.000000+00:00\".format(year, month)\n",
    "                print(\"{}, {}\".format(month, year))\n",
    "                end_time = \"{}-{}-28T00:00:00.000000+00:00\".format(year, month)\n",
    "                try:\n",
    "                    fetch_and_store_archival_tweets(city_name, query, start_time, end_time, month, year)\n",
    "                    store_logs(start_time, end_time)\n",
    "                except Exception as e:\n",
    "                    print(\"Start Time: {}, End Time: {}, Exception: {}\".format(start_time, end_time, e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2d88dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns = [\"Text\", \"CreatedAt\", \"TweetId\", \"FavoriteCount\", \"ScreenName\", \"UserId\", \"UserLocation\", \"UserFollowers\", \"UserCoordinate\", \"Place\"]\n",
    "\n",
    "# for city,list_of_tweets in tweets_for_cities.items():\n",
    "#     topic_count = 0\n",
    "#     for tweet_df in list_of_tweets:\n",
    "#         if len(tweet_df) > 0:\n",
    "#             tweets_df.columns = Columns\n",
    "#             topic_count += 1\n",
    "#             file_name = '~/Documents/Practice/TwitterData/{}/PublicSafety/Topic{}.csv'.format(city, topic_count)\n",
    "#             tweet_df.to_csv(file_name, index = False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
